{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SETTING UP BACKGROUND VARIABLES AND THE DATASETS!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm\n",
    "#^^ downloads an english dataset to help with dataset cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "assert sys.version_info.major == 3 and sys.version_info.minor == 11\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import (AutoTokenizer, Trainer, DataCollatorWithPadding, TrainingArguments, DebertaTokenizer, AutoModelForSequenceClassification)\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tinderdata\\\\tinder_google_play_reviews.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicrosoft/deberta-v3-small\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#load and drop everything except for the ID, the score given, and the text\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m tinder_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtinderdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtinder_google_play_reviews.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m amazon_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamazondata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mReviews.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Drop unwanted columns\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tinderdata\\\\tinder_google_play_reviews.csv'"
     ]
    }
   ],
   "source": [
    "model_path = 'microsoft/deberta-v3-small'\n",
    "\n",
    "#load and drop everything except for the ID, the score given, and the text\n",
    "tinder_df = pd.read_csv(r'tinderdata\\tinder_google_play_reviews.csv')\n",
    "amazon_df = pd.read_csv(r'amazondata\\Reviews.csv')\n",
    "\n",
    "# Drop unwanted columns\n",
    "tinder_df = tinder_df.drop(columns=[\n",
    "    'userName', 'userImage', 'reviewCreatedVersion', 'at', 'replyContent', 'repliedAt', 'appVersion'\n",
    "])\n",
    "\n",
    "amazon_df = amazon_df.drop(columns=[\n",
    "    'ProductId', 'UserId', 'ProfileName', 'Time'\n",
    "])\n",
    "\n",
    "# Initializes classes and IDs for the mdoel\n",
    "classes = [\"Not Satisfied\", \"Somewhat Satisfied\", \"Satisfied\"]\n",
    "labels_class = [0, 1, 2]\n",
    "class2id = {class_:id for id, class_ in enumerate(classes)}\n",
    "id2class = {id:class_ for class_, id in class2id.items()}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import label\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")# Load English model that defines lemmatization and stopwords\n",
    "\n",
    "def stop_words_and_lemmatize_texts(texts):\n",
    "    lemmatized_texts = []\n",
    "    for doc in nlp.pipe(texts, batch_size=1000):\n",
    "        filtered_lemmas = [\n",
    "            token.lemma_ for token in doc\n",
    "            if not token.is_punct and not token.is_space and not token.is_stop\n",
    "        ]\n",
    "        lemmatized_texts.append(\" \".join(filtered_lemmas))\n",
    "    return lemmatized_texts\n",
    "\n",
    "# ChatGPT helped code it - but we do know how to do regex!\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[^a-z0-9\\s.,!?]', '', text)  # Remove special chars (keep basic punctuation)\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove excessive whitespace\n",
    "    return text.strip()\n",
    "\n",
    "def clean_dataframe(df, text_column):\n",
    "    df = df.copy()  # make an explicit copy to avoid chained assignment issues\n",
    "    df.loc[:, text_column] = df[text_column].astype(str).apply(clean_text)  # Clean with regex\n",
    "    df.loc[:, text_column] = stop_words_and_lemmatize_texts(df[text_column])  # Lemmatize & remove stopwords\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning Block\n",
    "\n",
    "#===================================================\n",
    "#1) Drop duplicates\n",
    "\n",
    "a_df_unique = amazon_df.drop_duplicates(subset='Text')\n",
    "t_df_unique = tinder_df.drop_duplicates(subset='content')\n",
    "\n",
    "\n",
    "#===================================================\n",
    "#2 Drop 0 rated helpful reviews. Reviews should be rated helpful at least.\n",
    "\n",
    "a_df_filtered = a_df_unique[a_df_unique['HelpfulnessDenominator'] <= (a_df_unique['HelpfulnessNumerator']*2)] #Basically, get rid of all rows that have less than 1:2 helpful to non-helpful reviews. \n",
    "a_df_filtered_2 = a_df_filtered[a_df_filtered['HelpfulnessNumerator'] != 0]\n",
    "\n",
    "t_df_filtered = t_df_unique[t_df_unique['thumbsUpCount'] != 0]\n",
    "\n",
    "#===================================================\n",
    "\n",
    "# Extra: Miniature version of dataset to test smaller chunks of data in the interest of time and my computer's health\n",
    "percent_used = 0.005\n",
    "\n",
    "mini_amazon_df = a_df_filtered_2.sample(frac=percent_used, random_state=42)\n",
    "mini_tinder_df = t_df_filtered.sample(frac=percent_used, random_state=42)\n",
    "#===================================================\n",
    "\n",
    "#3 standardize all text (lemmatize and drop stopwords)\n",
    "a_df_cleaned = clean_dataframe(mini_amazon_df, \"Text\")\n",
    "t_df_cleaned = clean_dataframe(mini_tinder_df, \"content\")\n",
    "\n",
    "#===================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Id  HelpfulnessNumerator  HelpfulnessDenominator  Score  \\\n",
      "67333    67334                     5                       7      1   \n",
      "47358    47359                     1                       1      1   \n",
      "530169  530170                     4                       4      5   \n",
      "159483  159484                     1                       1      4   \n",
      "495351  495352                     3                       3      5   \n",
      "\n",
      "                                   Summary  \\\n",
      "67333                       Skinny Noodles   \n",
      "47358                      Not worth it...   \n",
      "530169  Great Price Delivered to Your Door   \n",
      "159483                      Nice in coffee   \n",
      "495351                         Maple Syrup   \n",
      "\n",
      "                                                     Text        Satisfaction  \\\n",
      "67333   miracle noodle aka skinny noodle disgusting th...       Not Satisfied   \n",
      "47358   well buy half piece large size cheap pos produ...       Not Satisfied   \n",
      "530169  club cracker arrive fresh good shape buck good...           Satisfied   \n",
      "159483  subtle almond butterscotch flavor tasty coffee...  Somewhat Satisfied   \n",
      "495351  love real thing meet expectation price right g...           Satisfied   \n",
      "\n",
      "        label  \n",
      "67333       0  \n",
      "47358       0  \n",
      "530169      2  \n",
      "159483      1  \n",
      "495351      2  \n"
     ]
    }
   ],
   "source": [
    "# 4. Bin into classes using pd.cut, converting previous scores of 1-5 to a class 0, 1, or 2 (not saitsfied, somewhat satisfied, satisfied)\n",
    "\n",
    "a_df_cleaned['Satisfaction'] = pd.cut(\n",
    "    a_df_cleaned['Score'], bins=[0, 3, 4, 5],\n",
    "    labels=classes, right=True, include_lowest=True\n",
    ")\n",
    "t_df_cleaned['Satisfaction'] = pd.cut(\n",
    "    t_df_cleaned['score'], bins=[0, 3, 4, 5],\n",
    "    labels=classes, right=True, include_lowest=True\n",
    ")\n",
    "\n",
    "# Map satisfaction text to int labels\n",
    "\n",
    "a_df_cleaned['Satisfaction'] = a_df_cleaned['Satisfaction'].astype(str)\n",
    "t_df_cleaned['Satisfaction'] = t_df_cleaned['Satisfaction'].astype(str)\n",
    "\n",
    "a_df_cleaned[\"label\"] = a_df_cleaned[\"Satisfaction\"].map(class2id).astype(int)\n",
    "t_df_cleaned[\"label\"] = t_df_cleaned[\"Satisfaction\"].map(class2id).astype(int)\n",
    "\n",
    "# Drop any rows with missing labels (in case of mapping issues)\n",
    "a_df_cleaned = a_df_cleaned.dropna(subset=[\"label\"])\n",
    "t_df_cleaned = t_df_cleaned.dropna(subset=[\"label\"])\n",
    "\n",
    "# # Now convert to Hugging Face Datasets bc its better for NLP\n",
    "# from datasets import Dataset\n",
    "\n",
    "# amazon_dataset = Dataset.from_pandas(a_df_cleaned[[\"Text\", \"label\"]].reset_index(drop=True))\n",
    "# tinder_dataset = Dataset.from_pandas(t_df_cleaned[[\"content\", \"label\"]].reset_index(drop=True))\n",
    "print(a_df_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**READ DATA FROM DATASET AND TOKENIZE IT!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef05f978dbaf46f3aec336153b7b5dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cca84f42de4d7b871264e213cfce44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bef0c86fb5147e7ba7adf880977d9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load an array for each pair of text/label for each dataset.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, clean_up_tokenization_spaces=True)\n",
    "\n",
    "combined_text = pd.concat([a_df_cleaned[\"Text\"], t_df_cleaned[\"content\"]], ignore_index=True)\n",
    "combined_labels = pd.concat([a_df_cleaned[\"label\"], t_df_cleaned[\"label\"]], ignore_index=True)\n",
    "\n",
    "df = pd.DataFrame({\"text\": combined_text, \"label\": combined_labels})\n",
    "\n",
    "examples = df[\"text\"].values\n",
    "Y_true = df[\"label\"].values\n",
    "\n",
    "# make training and validation sets through the training dataset\n",
    "examples_train, examples_test, labels_train, labels_test = train_test_split(examples, Y_true, test_size=0.05, random_state=42) #95% of the dataset is training, 5% for eval\n",
    "\n",
    "train = Dataset.from_dict( {\"text\": examples_train, \"label\": labels_train} )\n",
    "\n",
    "split = train.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = split['train']\n",
    "val_dataset = split['test']\n",
    "\n",
    "test_dataset = Dataset.from_dict( {\"text\": examples_test, \"label\": labels_test} )\n",
    "\n",
    "#Tokenize each dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SET UP VARIABLES AND FUNCTIONS FOR RESULTS LOG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181\n",
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import load_metric\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "f1_metric = load_metric(\"f1\")\n",
    "\n",
    "print(len(tokenized_train))\n",
    "print(len(tokenized_test))\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def sigmoid(x):\n",
    "   return 1/(1 + np.exp(-x))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    labels = labels.squeeze()\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    return {**accuracy, **f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SET UP MODEL AND TRAIN IT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, \n",
    "                                                        num_labels=len(classes), id2label=id2class, label2id=class2id, problem_type = \"single_label_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e26bd2f5b34205a98dd52ed1e06e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e214905863c4c9b919e067f8049ab74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5318787097930908, 'eval_accuracy': 0.7878787878787878, 'eval_f1': 0.7623992318170654, 'eval_runtime': 5.38, 'eval_samples_per_second': 24.535, 'eval_steps_per_second': 3.16, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557a4758732a4c7bb27d8cada4517ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5214681625366211, 'eval_accuracy': 0.8257575757575758, 'eval_f1': 0.799997196759454, 'eval_runtime': 4.8883, 'eval_samples_per_second': 27.003, 'eval_steps_per_second': 3.478, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22ba729482b4770ab750b4d80518da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46288469433784485, 'eval_accuracy': 0.8560606060606061, 'eval_f1': 0.8293300653594771, 'eval_runtime': 5.1138, 'eval_samples_per_second': 25.813, 'eval_steps_per_second': 3.324, 'epoch': 3.0}\n",
      "{'train_runtime': 903.7318, 'train_samples_per_second': 3.92, 'train_steps_per_second': 0.491, 'train_loss': 0.635158160785297, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=444, training_loss=0.635158160785297, metrics={'train_runtime': 903.7318, 'train_samples_per_second': 3.92, 'train_steps_per_second': 0.491, 'total_flos': 93635653080456.0, 'train_loss': 0.635158160785297, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(num_folds):\n",
    "\n",
    "#Best model for Deberta: batch_size = 8, learning_rate = 2e-5\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=\"my_awesome_model\",\n",
    "   per_device_train_batch_size = 8, #adjustable!\n",
    "   learning_rate= 2e-5, #adjustable!\n",
    "   num_train_epochs=3,\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   save_strategy=\"epoch\",\n",
    "   load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_train,\n",
    "   eval_dataset=tokenized_val,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST THE MODEL AND RUN PRINT RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ffe101451943db83a0f4bcf1549852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS LOG:\n",
      "F1: 0.8064449648711944\n",
      "MACROS: Precision: 0.5906932573599241  Recall: 0.5506535947712418 \n",
      "MICROS: Precision: 0.8285714285714286  Recall: 0.8285714285714286 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "TESTING_SET = tokenized_test\n",
    "\n",
    "\n",
    "predictions = trainer.predict(TESTING_SET)\n",
    "\n",
    "probs = sigmoid(torch.from_numpy(predictions.predictions))\n",
    "\n",
    "#Mostly ChatGPT\n",
    "print(f\"RESULTS LOG:\")\n",
    "\n",
    "pred_class = np.argmax(probs, axis=1)  # predicted class index per example\n",
    "\n",
    "print(f\"F1: {f1_score(y_true=TESTING_SET['label'], y_pred=pred_class, average='weighted')}\")\n",
    "\n",
    "# Precision and recall (macro-average across labels)\n",
    "precision_macro = precision_score(pred_class, labels_test, average='macro')\n",
    "recall_macro = recall_score(pred_class, labels_test, average='macro')\n",
    "\n",
    "# Precision and recall (micro-average across all samples and labels)\n",
    "precision_micro = precision_score(pred_class, labels_test, average='micro')\n",
    "recall_micro = recall_score(pred_class, labels_test, average='micro')\n",
    "\n",
    "print(f\"MACROS: Precision: {precision_macro}  Recall: {recall_macro} \")\n",
    "print(f\"MICROS: Precision: {precision_micro}  Recall: {recall_micro} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semeval1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
